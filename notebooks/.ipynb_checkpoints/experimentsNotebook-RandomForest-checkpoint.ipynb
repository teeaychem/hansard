{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for CS224U Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import csv\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import sst\n",
    "import scipy.stats\n",
    "from sgd_classifier import BasicSGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/declan/anaconda3/envs/nlu/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tf_rnn_classifier import TfRNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsmdata_home = 'vsmdata'\n",
    "\n",
    "glove_home = os.path.join(vsmdata_home, 'glove.6B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_array_from_csv(inputcsv):\n",
    "    out = []\n",
    "    with open(inputcsv, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for q in reader:\n",
    "            out.append(q)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = read_array_from_csv('data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anon_new_train = read_array_from_csv('data/anon_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "anon_new_test = read_array_from_csv('data/anon_test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SST Machinery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hansard_reader(\n",
    "        src_filename,\n",
    "        class_func=None):\n",
    "    \"\"\"Overview\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    src_filename : str\n",
    "        Full path to the file to be read.\n",
    "    class_func : None, or function mapping labels to labels or None\n",
    "        If this is None, then the original 5-way labels are returned.\n",
    "        Other options: `binary_class_func` and `ternary_class_func`\n",
    "        (or you could write your own).\n",
    "\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    (tree, label)\n",
    "        nltk.Tree, str in {'0','1','2','3','4'}\n",
    "\n",
    "    \"\"\"\n",
    "    if class_func is None:\n",
    "        class_func = lambda x: x\n",
    "    with open(src_filename, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for q in reader:\n",
    "            yield (q[0], class_func(q[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a reader for each dataset, both for train and for test.\n",
    "\n",
    "First, the standard data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_reader(**kwargs):\n",
    "    \"\"\"Convenience function for reading the train file, full-trees only.\"\"\"\n",
    "    src = 'data/train_data.csv'\n",
    "    return hansard_reader(src,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reader(**kwargs):\n",
    "    \"\"\"Convenience function for reading the train file, full-trees only.\"\"\"\n",
    "    src = 'data/test_data.csv'\n",
    "    return hansard_reader(src,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the anonymised data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anon_train_reader(**kwargs):\n",
    "    src = 'data/anon_train_data.csv'\n",
    "    return hansard_reader(src,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anon_test_reader(**kwargs):\n",
    "    src = 'data/anon_test_data.csv'\n",
    "    return hansard_reader(src,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test readers won't be used until the *very* end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cas_to_gov(label):\n",
    "    if label == 'cas':\n",
    "        return 'gov'\n",
    "    else:\n",
    "        return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup a grid search like above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A unigrams feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigrams_phi(question):\n",
    "    \"\"\"The basis for a unigrams feature function.\n",
    "    Parameters\n",
    "    ----------\n",
    "    question : string\n",
    "        The question to represent.\n",
    "    \n",
    "    Returns\n",
    "    -------    \n",
    "    defaultdict\n",
    "        A map from strings to their counts in the question. (Counter maps a \n",
    "        list to a dict of counts of the elements in that list.)\n",
    "    \"\"\"\n",
    "    unigrams = {}\n",
    "    for word in question.split() :\n",
    "        unigrams[word] = unigrams.get(word, 0) + 1\n",
    "    return unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bigrams feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams_phi(question):\n",
    "    \"\"\"The basis for a unigrams feature function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tree : nltk.tree\n",
    "        The tree to represent.\n",
    "    \n",
    "    Returns\n",
    "    -------    \n",
    "    defaultdict\n",
    "        A map from strings to their counts in `tree`. (Counter maps a \n",
    "        list to a dict of counts of the elements in that list.)\n",
    "    \n",
    "    \"\"\"\n",
    "    bigrams = {}\n",
    "    qarray = question.split()\n",
    "    for i in range(0, len(qarray)-1) :\n",
    "        big = qarray[i] + '_' + qarray[i+1]\n",
    "        bigrams[big] = bigrams.get(big, 0) + 1\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic bag-of-words unigrams and bigrams feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_bigrams_phi(question):\n",
    "    grams = unigrams_phi(question)\n",
    "    grams.update(bigrams_phi(question))\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that *friend* seems to be a good indicator. What happens if we only give the classifier that feature? Or unigrams without it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_friend_phi(question):\n",
    "    if 'friend' in question.lower().split():\n",
    "        return {'friend':1}\n",
    "    else:\n",
    "        return {'friend':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_friends_phi(question):\n",
    "    unigrams = {}\n",
    "    for word in question.split() :\n",
    "        if word.lower() is not 'friend':\n",
    "            unigrams[word.lower()] = unigrams.get(word.lower(), 0) + 1\n",
    "    return unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sst.build_dataset(anon_train_reader, bigrams_phi, cas_to_gov, vectorize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['X']\n",
    "y_train = train['y']\n",
    "X_assess = None\n",
    "y_assess = None\n",
    "if None == None:\n",
    "     X_train, X_assess, y_train, y_assess = train_test_split(\n",
    "            X_train, y_train, train_size=0.7, test_size=None)\n",
    "else:\n",
    "    # Assessment dataset using the training vectorizer:\n",
    "    assess = sst.build_dataset(\n",
    "        assess_reader,\n",
    "        phi,\n",
    "        class_func,\n",
    "        vectorizer=train['vectorizer'],\n",
    "        vectorize=vectorize)\n",
    "    X_assess, y_assess = assess['X'], assess['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': [20, 25, 35, 50], \n",
    "                  'max_features': ['sqrt', 'log2'],\n",
    "                  'n_jobs': [-1],\n",
    "                 'bootstrap' : [True, False],\n",
    "                 'min_samples_leaf' : [1, 5, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_classifier = GridSearchCV(RandomForestClassifier(), parameters, scoring='f1_macro',verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[CV] bootstrap=True, max_features=sqrt, min_samples_leaf=1, n_estimators=20, n_jobs=-1 \n"
     ]
    }
   ],
   "source": [
    "grid_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'bootstrap': True, 'max_features': None, 'n_estimators': 20, 'n_jobs': -1}\n",
      "Best score: 0.699\n",
      "Accuracy: 0.742\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.619     0.573     0.595      1009\n",
      "        opp      0.796     0.826     0.811      2041\n",
      "\n",
      "avg / total      0.738     0.742     0.739      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params\", grid_classifier.best_params_)\n",
    "print(\"Best score: %0.03f\" % grid_classifier.best_score_)\n",
    "final_mod = grid_classifier.best_estimator_\n",
    "predictions = final_mod.predict(X_assess)\n",
    "print('Accuracy: %0.03f' % sst.accuracy_score(y_assess, predictions))\n",
    "print(classification_report(y_assess, predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
