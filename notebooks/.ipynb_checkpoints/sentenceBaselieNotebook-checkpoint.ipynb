{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for CS224U Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import csv\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import sst\n",
    "import scipy.stats\n",
    "from sgd_classifier import BasicSGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/declan/anaconda3/envs/nlu/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tf_rnn_classifier import TfRNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsmdata_home = 'vsmdata'\n",
    "\n",
    "glove_home = os.path.join(vsmdata_home, 'glove.6B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_array_from_csv(inputcsv):\n",
    "    out = []\n",
    "    with open(inputcsv, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for q in reader:\n",
    "            out.append(q)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = read_array_from_csv('data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "anon_new_train = read_array_from_csv('data/anon_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "anon_new_test = read_array_from_csv('data/anon_test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SST Machinery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hansard_reader(\n",
    "        src_filename,\n",
    "        class_func=None):\n",
    "    \"\"\"Overview\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    src_filename : str\n",
    "        Full path to the file to be read.\n",
    "    class_func : None, or function mapping labels to labels or None\n",
    "        If this is None, then the original 5-way labels are returned.\n",
    "        Other options: `binary_class_func` and `ternary_class_func`\n",
    "        (or you could write your own).\n",
    "\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    (tree, label)\n",
    "        nltk.Tree, str in {'0','1','2','3','4'}\n",
    "\n",
    "    \"\"\"\n",
    "    if class_func is None:\n",
    "        class_func = lambda x: x\n",
    "    with open(src_filename, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for q in reader:\n",
    "            yield (q[0], class_func(q[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a reader for each dataset, both for train and for test.\n",
    "\n",
    "First, the standard data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_reader(**kwargs):\n",
    "    \"\"\"Convenience function for reading the train file, full-trees only.\"\"\"\n",
    "    src = 'data/train_data.csv'\n",
    "    return hansard_reader(src,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reader(**kwargs):\n",
    "    \"\"\"Convenience function for reading the train file, full-trees only.\"\"\"\n",
    "    src = 'data/test_data.csv'\n",
    "    return hansard_reader(src,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the anonymised data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anon_train_reader(**kwargs):\n",
    "    src = 'data/anon_train_data.csv'\n",
    "    return hansard_reader(src,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anon_test_reader(**kwargs):\n",
    "    src = 'data/anon_test_data.csv'\n",
    "    return hansard_reader(src,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test readers won't be used until the *very* end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cas_to_gov(label):\n",
    "    if label == 'cas':\n",
    "        return 'gov'\n",
    "    else:\n",
    "        return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words Feature Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A unigrams feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigrams_phi(question):\n",
    "    \"\"\"The basis for a unigrams feature function.\n",
    "    Parameters\n",
    "    ----------\n",
    "    question : string\n",
    "        The question to represent.\n",
    "    \n",
    "    Returns\n",
    "    -------    \n",
    "    defaultdict\n",
    "        A map from strings to their counts in the question. (Counter maps a \n",
    "        list to a dict of counts of the elements in that list.)\n",
    "    \"\"\"\n",
    "    unigrams = {}\n",
    "    for word in question.split() :\n",
    "        unigrams[word] = unigrams.get(word, 0) + 1\n",
    "    return unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bigrams feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams_phi(question):\n",
    "    \"\"\"The basis for a unigrams feature function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tree : nltk.tree\n",
    "        The tree to represent.\n",
    "    \n",
    "    Returns\n",
    "    -------    \n",
    "    defaultdict\n",
    "        A map from strings to their counts in `tree`. (Counter maps a \n",
    "        list to a dict of counts of the elements in that list.)\n",
    "    \n",
    "    \"\"\"\n",
    "    bigrams = {}\n",
    "    qarray = question.split()\n",
    "    for i in range(0, len(qarray)-1) :\n",
    "        big = qarray[i] + '_' + qarray[i+1]\n",
    "        bigrams[big] = bigrams.get(big, 0) + 1\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic bag-of-words unigrams and bigrams feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_bigrams_phi(question):\n",
    "    grams = unigrams_phi(question)\n",
    "    grams.update(bigrams_phi(question))\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that *friend* seems to be a good indicator. What happens if we only give the classifier that feature? Or unigrams without it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_friend_phi(question):\n",
    "    if 'friend' in question.lower().split():\n",
    "        return {'friend':1}\n",
    "    else:\n",
    "        return {'friend':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_friends_phi(question):\n",
    "    unigrams = {}\n",
    "    for word in question.split() :\n",
    "        if word.lower() is not 'friend':\n",
    "            unigrams[word.lower()] = unigrams.get(word.lower(), 0) + 1\n",
    "    return unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier Baseline\n",
    "Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_basic_sgd_classifier(X, y):    \n",
    "    \"\"\"Wrapper for `BasicSGDClassifier`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2d np.array\n",
    "        The matrix of features, one example per row.        \n",
    "    y : list\n",
    "        The list of labels for rows in `X`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    BasicSGDClassifier\n",
    "        A trained `BasicSGDClassifier` instance.\n",
    "    \n",
    "    \"\"\"    \n",
    "    mod = BasicSGDClassifier()\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, an SGD classifier trained on unigrams for the unmodified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.775\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.707     0.587     0.642      1046\n",
      "        opp      0.802     0.873     0.836      2004\n",
      "\n",
      "avg / total      0.770     0.775     0.769      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = sst.experiment(\n",
    "    unigrams_phi,\n",
    "    fit_basic_sgd_classifier,\n",
    "    train_reader=train_reader, \n",
    "    assess_reader=None, \n",
    "    train_size=0.7,\n",
    "    class_func=cas_to_gov,\n",
    "    score_func=utils.safe_macro_f1,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, an SGD classifier trained on unigrams for the modified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.775\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.707     0.587     0.642      1046\n",
      "        opp      0.802     0.873     0.836      2004\n",
      "\n",
      "avg / total      0.770     0.775     0.769      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = sst.experiment(\n",
    "    unigrams_phi,\n",
    "    fit_basic_sgd_classifier,\n",
    "    train_reader=anon_train_reader, \n",
    "    assess_reader=None, \n",
    "    train_size=0.7,\n",
    "    class_func=cas_to_gov,\n",
    "    score_func=utils.safe_macro_f1,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, an SGD classifier trained on bigrams from the modified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.754\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.649     0.618     0.633      1047\n",
      "        opp      0.805     0.825     0.815      2003\n",
      "\n",
      "avg / total      0.752     0.754     0.753      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = sst.experiment(\n",
    "    bigrams_phi,\n",
    "    fit_basic_sgd_classifier,\n",
    "    train_reader=anon_train_reader, \n",
    "    assess_reader=None, \n",
    "    train_size=0.7,\n",
    "    class_func=cas_to_gov,\n",
    "    score_func=utils.safe_macro_f1,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_maxent_classifier(X, y):   \n",
    "    mod = LogisticRegression(fit_intercept=True)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we start with unigrams for the basic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.782\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.750     0.577     0.652      1079\n",
      "        opp      0.795     0.894     0.842      1971\n",
      "\n",
      "avg / total      0.779     0.782     0.775      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = sst.experiment(\n",
    "    unigrams_phi,\n",
    "    fit_maxent_classifier,\n",
    "    train_reader=train_reader, \n",
    "    assess_reader=None, \n",
    "    train_size=0.7,\n",
    "    class_func=cas_to_gov,\n",
    "    score_func=utils.safe_macro_f1,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now unigrams for the modified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.769\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.703     0.595     0.644      1072\n",
      "        opp      0.797     0.863     0.829      1978\n",
      "\n",
      "avg / total      0.764     0.769     0.764      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = sst.experiment(\n",
    "    unigrams_phi,\n",
    "    fit_maxent_classifier,\n",
    "    train_reader=anon_train_reader, \n",
    "    assess_reader=None, \n",
    "    train_size=0.7,\n",
    "    class_func=cas_to_gov,\n",
    "    score_func=utils.safe_macro_f1,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now bigrams on the modified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.769\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.703     0.595     0.644      1072\n",
      "        opp      0.797     0.863     0.829      1978\n",
      "\n",
      "avg / total      0.764     0.769     0.764      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = sst.experiment(\n",
    "    bigrams_phi,\n",
    "    fit_maxent_classifier,\n",
    "    train_reader=anon_train_reader, \n",
    "    assess_reader=None, \n",
    "    train_size=0.7,\n",
    "    class_func=cas_to_gov,\n",
    "    score_func=utils.safe_macro_f1,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression without using sst.experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, choose the feature function to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = unigrams_phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, choose the reader used for testing. (None gives a random split.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_reader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're doing a split, what size should we train on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, choose a function for the classes. (We probably want cas_to_gov.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_func = cas_to_gov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we want to vectorise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Classifier\n",
    "\n",
    "Which classifier are we to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make it into a training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(X, y):   \n",
    "    mod = classifier\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sst.build_dataset(train_reader, phi, class_func, vectorize=vectorize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the experiment\n",
    "\n",
    "First, get the data into standardised variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['X']\n",
    "y_train = train['y']\n",
    "X_assess = None\n",
    "y_assess = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're not using an assess_reader, do a split on the training data. Otherwise, read in the assessment dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if assess_reader == None:\n",
    "     X_train, X_assess, y_train, y_assess = train_test_split(\n",
    "            X_train, y_train, train_size=train_size, test_size=None)\n",
    "else:\n",
    "    # Assessment dataset using the training vectorizer:\n",
    "    assess = sst.build_dataset(\n",
    "        assess_reader,\n",
    "        phi,\n",
    "        class_func,\n",
    "        vectorizer=train['vectorizer'],\n",
    "        vectorize=vectorize)\n",
    "    X_assess, y_assess = assess['X'], assess['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment\n",
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = train_func(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mod.predict(X_assess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.768\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.677     0.603     0.638      1020\n",
      "        opp      0.807     0.853     0.829      1987\n",
      "\n",
      "avg / total      0.763     0.768     0.764      3007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %0.03f' % sst.accuracy_score(y_assess, predictions))\n",
    "print(classification_report(y_assess, predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be fairly straightforward. We do Logistic Regression again, but we use GloVe embeddings, rather than the bag of words embeddings from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Setup\n",
    "\n",
    "First, we need the GloVe lookup function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_lookup = utils.glove2dict(\n",
    "    os.path.join(glove_home, 'glove.6B.50d.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a feature function based on the GloVe embeddings. The important parameter here is how we combine vectors for different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vsm_words_phi(sentence, lookup, np_func=np.sum):\n",
    "    \"\"\"Represent `sentence` as a combination of the vector of its words.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tree : A string   \n",
    "    lookup : dict\n",
    "        From words to vectors.\n",
    "    np_func : function (default: np.sum)\n",
    "        A numpy matrix operation that can be applied columnwise, \n",
    "        like `np.mean`, `np.sum`, or `np.prod`. The requirement is that \n",
    "        the function take `axis=0` as one of its arguments (to ensure\n",
    "        columnwise combination) and that it return a vector of a \n",
    "        fixed length, no matter what the size of the tree is.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array, dimension `X.shape[1]`\n",
    "            \n",
    "    \"\"\"      \n",
    "    allvecs = np.array([lookup[w] for w in sentence.split() if w in lookup])    \n",
    "    if len(allvecs) == 0:\n",
    "        dim = len(next(iter(lookup.values())))\n",
    "        feats = np.zeros(dim)\n",
    "    else:       \n",
    "        feats = np_func(allvecs, axis=0)      \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_words_phi(sentence, np_func=np.sum):\n",
    "    return vsm_words_phi(sentence, glove_lookup, np_func=np_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the Training/Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sst.build_dataset(train_reader, glove_words_phi, class_func, vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['X']\n",
    "y_train = train['y']\n",
    "X_assess = None\n",
    "y_assess = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're not using an assess_reader, do a split on the training data. Otherwise, read in the assessment dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if assess_reader == None:\n",
    "     X_train, X_assess, y_train, y_assess = train_test_split(\n",
    "            X_train, y_train, train_size=train_size, test_size=None)\n",
    "else:\n",
    "    # Assessment dataset using the training vectorizer:\n",
    "    assess = sst.build_dataset(\n",
    "        assess_reader,\n",
    "        phi,\n",
    "        class_func,\n",
    "        vectorizer=train['vectorizer'],\n",
    "        vectorize=vectorize)\n",
    "    X_assess, y_assess = assess['X'], assess['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, we'll do some grid searching. In order to show how to make this work in general, here we'll step through the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a base model to do a grid search on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemod = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify a parameter grid to search over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'fit_intercept': [True, False], \n",
    "                  'C': [0.4, 0.6, 0.8, 1.0, 2.0, 3.0],\n",
    "                  'penalty': ['l1','l2']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many fold cross-validation? (Default is None.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What score metric should be used? (Some function is required here, unless the basemod provides its own.). Options include 'f1_macro', 'f1_micro' and 'accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'f1_macro'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_classifier = GridSearchCV(basemod, param_grid, cv=cv, scoring=scoring,verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.4, fit_intercept=True, penalty=l1, score=0.644543794940576, total=   4.2s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l1, score=0.665227082752856, total=   9.9s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   14.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l1, score=0.6361557844808419, total=   3.5s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   17.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l1, score=0.6396433754924321, total=   3.0s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   20.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l1, score=0.6061868716340213, total=   5.6s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l2 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   26.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l2, score=0.6427753561094345, total=   0.4s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l2 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   26.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l2, score=0.6635259277731884, total=   0.5s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l2 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   27.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l2, score=0.6396409552099758, total=   0.4s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l2 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   27.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l2, score=0.6396243291592129, total=   0.4s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l2 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   28.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l2, score=0.6152210028191704, total=   0.3s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l1, score=0.651792916481798, total=   3.4s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l1, score=0.6587110805860805, total=   4.2s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l1, score=0.6476042467510847, total=   3.6s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l1, score=0.6540214239214063, total=   3.0s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l1, score=0.6332325888017853, total=   3.2s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l2, score=0.6490377358490567, total=   0.2s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l2, score=0.6579755914275115, total=   0.3s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l2, score=0.6508159958671864, total=   0.3s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l2, score=0.6565601524781264, total=   0.2s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l2, score=0.6325097809310729, total=   0.3s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l1, score=0.643971659435577, total=   5.3s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l1, score=0.6669983680292958, total=  19.4s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l1, score=0.6349716101088732, total=   4.1s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l1, score=0.6378577817531306, total=   3.1s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l1, score=0.6087094188276033, total=   5.9s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l2, score=0.6427753561094345, total=   0.3s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l2, score=0.6610718464895191, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l2, score=0.6396409552099758, total=   0.3s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l2, score=0.6396243291592129, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l2, score=0.6158562787576929, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l1, score=0.651792916481798, total=   4.0s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l1, score=0.6591914154872724, total=   7.0s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l1, score=0.6508159958671864, total=   3.0s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l1, score=0.6551149831778559, total=   3.1s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l1, score=0.6336913388543823, total=   3.4s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l2, score=0.6501148100552043, total=   0.3s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l2, score=0.6573683450698578, total=   0.3s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l2, score=0.6508159958671864, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l2, score=0.6571676551424852, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l2, score=0.631919598422528, total=   0.3s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l1, score=0.6445705927205391, total=   5.4s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l1, score=0.662911549166623, total=  23.6s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l1, score=0.6361338112217516, total=   4.7s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l1, score=0.6384336216669436, total=   3.5s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l1, score=0.6092804798687151, total=   7.8s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l2, score=0.6416033885855229, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l2, score=0.6610718464895191, total=   0.3s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l2, score=0.6396409552099758, total=   0.3s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l2, score=0.6396243291592129, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l2, score=0.6140062715588773, total=   0.3s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l1, score=0.6529999463078378, total=   3.8s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l1, score=0.6602776563118175, total=   8.8s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l1, score=0.6491452590053068, total=   3.5s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l1, score=0.6559530851060669, total=   3.9s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l1, score=0.6347276915430493, total=   4.0s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l2, score=0.6501148100552043, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l2, score=0.6562824012860635, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l2, score=0.6508159958671864, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l2, score=0.6565601524781264, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l2, score=0.631919598422528, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l1, score=0.6445705927205391, total=   5.6s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l1, score=0.662911549166623, total=  26.3s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1.0, fit_intercept=True, penalty=l1, score=0.6372937496921637, total=   3.7s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l1, score=0.6384336216669436, total=   3.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l1, score=0.6104961338101258, total=   5.5s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l2, score=0.6422003741591371, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l2, score=0.6622281832519901, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l2, score=0.6396409552099758, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l2, score=0.6396243291592129, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l2, score=0.6152797856199927, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l1, score=0.6523962264150944, total=   3.9s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l1, score=0.6602776563118175, total=  13.0s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l1, score=0.6497472544579261, total=   3.0s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l1, score=0.6565601524781264, total=   3.0s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l1, score=0.6336197388455185, total=   4.0s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l2, score=0.6501148100552043, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l2, score=0.6562824012860635, total=   0.3s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l2, score=0.6508159958671864, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l2, score=0.6571676551424852, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l2, score=0.6308084373242723, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l1, score=0.6422003741591371, total=   6.3s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l1, score=0.6640704604515818, total=   4.8s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l1, score=0.6343980829565948, total=   4.8s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l1, score=0.6384336216669436, total=   3.2s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l1, score=0.6111361994219653, total=   8.4s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l2, score=0.6439450014301217, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l2, score=0.6610718464895191, total=   0.4s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l2, score=0.6396409552099758, total=   1.4s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l2, score=0.6396243291592129, total=   0.3s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l2, score=0.6152797856199927, total=   0.7s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l1, score=0.651792916481798, total=   5.1s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l1, score=0.655800285293116, total=  21.4s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l1, score=0.650349642128232, total=   3.5s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l1, score=0.6582519743871011, total=   3.6s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l1, score=0.6352410608826372, total=   4.0s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l2, score=0.6501148100552043, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l2, score=0.6573683450698578, total=   0.3s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l2, score=0.6508159958671864, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l2, score=0.6571676551424852, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l2, score=0.631919598422528, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l1, score=0.643373248394977, total=  10.0s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l1, score=0.6622977452033052, total=  31.9s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l1, score=0.6349895079069279, total=   4.3s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l1, score=0.6372448979591836, total=   4.6s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l1, score=0.6134945410057003, total=   9.0s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l2, score=0.643373248394977, total=   0.2s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l2, score=0.6628417062989733, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l2, score=0.6396409552099758, total=   0.2s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l2, score=0.6396243291592129, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l2, score=0.6158562787576929, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l1, score=0.6511900135429547, total=   4.9s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l1, score=0.6568889047538307, total=  22.3s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l1, score=0.6497472544579261, total=   4.5s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l1, score=0.6582519743871011, total=   3.6s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l1, score=0.6341359019987906, total=   4.7s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l2 ..........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=3.0, fit_intercept=False, penalty=l2, score=0.6501148100552043, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l2, score=0.6562824012860635, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l2, score=0.6508159958671864, total=   0.2s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l2, score=0.6571676551424852, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l2, score=0.6308084373242723, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'fit_intercept': [True, False], 'C': [0.4, 0.6, 0.8, 1.0, 2.0, 3.0], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_macro', verbose=10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get some reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 0.8, 'fit_intercept': False, 'penalty': 'l1'}\n",
      "Best score: 0.651\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params\", grid_classifier.best_params_)\n",
    "print(\"Best score: %0.03f\" % grid_classifier.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mod = grid_classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = final_mod.predict(X_assess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.708\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.613     0.424     0.501      1055\n",
      "        opp      0.738     0.859     0.794      1995\n",
      "\n",
      "avg / total      0.695     0.708     0.693      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %0.03f' % sst.accuracy_score(y_assess, predictions))\n",
    "print(classification_report(y_assess, predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_grid(np_func=np.sum):\n",
    "    def glove_words_phi(sentence, np_func=np.sum):\n",
    "        return vsm_words_phi(sentence, glove_lookup, np_func=np_func)\n",
    "    train = sst.build_dataset(train_reader, glove_words_phi, class_func, vectorize=False)\n",
    "    X_train = train['X']\n",
    "    y_train = train['y']\n",
    "    X_assess = None\n",
    "    y_assess = None\n",
    "    if assess_reader == None:\n",
    "         X_train, X_assess, y_train, y_assess = train_test_split(\n",
    "                X_train, y_train, train_size=train_size, test_size=None)\n",
    "    else:\n",
    "        # Assessment dataset using the training vectorizer:\n",
    "        assess = sst.build_dataset(\n",
    "            assess_reader,\n",
    "            phi,\n",
    "            class_func,\n",
    "            vectorizer=train['vectorizer'],\n",
    "            vectorize=vectorize)\n",
    "        X_assess, y_assess = assess['X'], assess['y']\n",
    "    \n",
    "    grid_classifier = GridSearchCV(LogisticRegression(), {'fit_intercept': [True, False], \n",
    "                  'C': [0.4, 0.6, 0.8, 1.0, 2.0, 3.0],\n",
    "                  'penalty': ['l1','l2']}, cv=5, scoring='f1_macro',verbose=1)\n",
    "    grid_classifier.fit(X_train, y_train)\n",
    "    print(\"Best params\", grid_classifier.best_params_)\n",
    "    print(\"Best score: %0.03f\" % grid_classifier.best_score_)\n",
    "    final_mod = grid_classifier.best_estimator_\n",
    "    predictions = final_mod.predict(X_assess)\n",
    "    print('Accuracy: %0.03f' % sst.accuracy_score(y_assess, predictions))\n",
    "    print(classification_report(y_assess, predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 0.4, 'fit_intercept': False, 'penalty': 'l1'}\n",
      "Best score: 0.649\n",
      "Accuracy: 0.711\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.624     0.400     0.487      1047\n",
      "        opp      0.736     0.874     0.799      2003\n",
      "\n",
      "avg / total      0.697     0.711     0.692      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_logistic_grid(np.add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 1.0, 'fit_intercept': False, 'penalty': 'l1'}\n",
      "Best score: 0.641\n",
      "Accuracy: 0.711\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.643     0.411     0.502      1079\n",
      "        opp      0.731     0.875     0.796      1971\n",
      "\n",
      "avg / total      0.700     0.711     0.692      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_logistic_grid(np.prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 2.0, 'fit_intercept': False, 'penalty': 'l2'}\n",
      "Best score: 0.643\n",
      "Accuracy: 0.696\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.623     0.405     0.491      1105\n",
      "        opp      0.718     0.861     0.783      1945\n",
      "\n",
      "avg / total      0.684     0.696     0.677      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_logistic_grid(np.multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed: 10.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 0.6, 'fit_intercept': False, 'penalty': 'l1'}\n",
      "Best score: 0.640\n",
      "Accuracy: 0.712\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.629     0.439     0.517      1071\n",
      "        opp      0.739     0.860     0.795      1979\n",
      "\n",
      "avg / total      0.700     0.712     0.697      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_logistic_grid(np.mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should use the tensorflow RNN set-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Input Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(question.split(), label) for question, label in train_reader(class_func=cas_to_gov)]\n",
    "X, y = zip(*train_data)\n",
    "X_rnn_train = list(X)\n",
    "y_rnn_train = list(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have a devoted dev set, make a 70-30 split in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rnn_train, X_rnn_assess, y_rnn_train, y_rnn_assess = train_test_split(X_rnn_train, y_rnn_train, train_size=0.7, test_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorflow implementation requires that we specify a maximum length up front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 1,123\n",
      "Min sequence length: 0\n",
      "Mean sequence length: 71.78\n",
      "Median sequence length: 69.00\n",
      "Sequences longer than 150: 225 of 7,115\n"
     ]
    }
   ],
   "source": [
    "utils.sequence_length_report(X_rnn_train, potential_max_length=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, we might take this maximum length to be 150."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hansard_full_train_vocab = sst.get_vocab(X_rnn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hansard_full_train_vocab has 35,337 items\n"
     ]
    }
   ],
   "source": [
    "print(\"hansard_full_train_vocab has {:,} items\".format(len(hansard_full_train_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hansard_train_vocab = sst.get_vocab(X_rnn_train, n_words=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rnn = TfRNNClassifier(\n",
    "    hansard_train_vocab,\n",
    "    embed_dim=50,\n",
    "    hidden_dim=50,\n",
    "    max_length=150,\n",
    "    hidden_activation=tf.nn.tanh,\n",
    "    cell_class=tf.nn.rnn_cell.LSTMCell,\n",
    "    train_embedding=True,\n",
    "    max_iter=10,\n",
    "    eta=0.05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 10: loss: 4.548222303390503"
     ]
    }
   ],
   "source": [
    "_ = tf_rnn.fit(X_rnn_train, y_rnn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rnn_dev_predictions = tf_rnn.predict(X_rnn_assess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov       0.00      0.00      0.00      1039\n",
      "        opp       0.66      1.00      0.79      2011\n",
      "\n",
      "avg / total       0.43      0.66      0.52      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_rnn_assess, tf_rnn_dev_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long/Short Term Memory Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
