{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for CS224U Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import csv\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import sst\n",
    "import scipy.stats\n",
    "from sgd_classifier import BasicSGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/declan/anaconda3/envs/nlu/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tf_rnn_classifier import TfRNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsmdata_home = 'vsmdata'\n",
    "\n",
    "glove_home = os.path.join(vsmdata_home, 'glove.6B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_array_from_csv(inputcsv):\n",
    "    out = []\n",
    "    with open(inputcsv, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for q in reader:\n",
    "            out.append(q)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = read_array_from_csv('data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "anon_new_train = read_array_from_csv('data/anon_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anon_new_test = read_array_from_csv('data/anon_test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SST Machinery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hansard_reader(\n",
    "        src_filename,\n",
    "        class_func=None):\n",
    "    \"\"\"Overview\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    src_filename : str\n",
    "        Full path to the file to be read.\n",
    "    class_func : None, or function mapping labels to labels or None\n",
    "        If this is None, then the original 5-way labels are returned.\n",
    "        Other options: `binary_class_func` and `ternary_class_func`\n",
    "        (or you could write your own).\n",
    "\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    (tree, label)\n",
    "        nltk.Tree, str in {'0','1','2','3','4'}\n",
    "\n",
    "    \"\"\"\n",
    "    if class_func is None:\n",
    "        class_func = lambda x: x\n",
    "    with open(src_filename, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for q in reader:\n",
    "            yield (q[0], class_func(q[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a reader for each dataset, both for train and for test.\n",
    "\n",
    "First, the standard data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_reader(**kwargs):\n",
    "    \"\"\"Convenience function for reading the train file, full-trees only.\"\"\"\n",
    "    src = 'data/train_data.csv'\n",
    "    return hansard_reader(src,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reader(**kwargs):\n",
    "    \"\"\"Convenience function for reading the train file, full-trees only.\"\"\"\n",
    "    src = 'data/test_data.csv'\n",
    "    return hansard_reader(src,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the anonymised data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anon_train_reader(**kwargs):\n",
    "    src = 'data/anon_train_data.csv'\n",
    "    return hansard_reader(src,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anon_test_reader(**kwargs):\n",
    "    src = 'data/anon_test_data.csv'\n",
    "    return hansard_reader(src,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test readers won't be used until the *very* end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cas_to_gov(label):\n",
    "    if label == 'cas':\n",
    "        return 'gov'\n",
    "    else:\n",
    "        return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words Feature Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A unigrams feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigrams_phi(question):\n",
    "    \"\"\"The basis for a unigrams feature function.\n",
    "    Parameters\n",
    "    ----------\n",
    "    question : string\n",
    "        The question to represent.\n",
    "    \n",
    "    Returns\n",
    "    -------    \n",
    "    defaultdict\n",
    "        A map from strings to their counts in the question. (Counter maps a \n",
    "        list to a dict of counts of the elements in that list.)\n",
    "    \"\"\"\n",
    "    unigrams = {}\n",
    "    for word in question.split() :\n",
    "        unigrams[word] = unigrams.get(word, 0) + 1\n",
    "    return unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bigrams feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams_phi(question):\n",
    "    \"\"\"The basis for a unigrams feature function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tree : nltk.tree\n",
    "        The tree to represent.\n",
    "    \n",
    "    Returns\n",
    "    -------    \n",
    "    defaultdict\n",
    "        A map from strings to their counts in `tree`. (Counter maps a \n",
    "        list to a dict of counts of the elements in that list.)\n",
    "    \n",
    "    \"\"\"\n",
    "    bigrams = {}\n",
    "    qarray = question.split()\n",
    "    for i in range(0, len(qarray)-1) :\n",
    "        big = qarray[i] + '_' + qarray[i+1]\n",
    "        bigrams[big] = bigrams.get(big, 0) + 1\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic bag-of-words unigrams and bigrams feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_bigrams_phi(question):\n",
    "    grams = unigrams_phi(question)\n",
    "    grams.update(bigrams_phi(question))\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that *friend* seems to be a good indicator. What happens if we only give the classifier that feature? Or unigrams without it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_friend_phi(question):\n",
    "    if 'friend' in question.lower().split():\n",
    "        return {'friend':1}\n",
    "    else:\n",
    "        return {'friend':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_friends_phi(question):\n",
    "    unigrams = {}\n",
    "    for word in question.split() :\n",
    "        if word.lower() is not 'friend':\n",
    "            unigrams[word.lower()] = unigrams.get(word.lower(), 0) + 1\n",
    "    return unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier Baseline\n",
    "Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_basic_sgd_classifier(X, y):    \n",
    "    \"\"\"Wrapper for `BasicSGDClassifier`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2d np.array\n",
    "        The matrix of features, one example per row.        \n",
    "    y : list\n",
    "        The list of labels for rows in `X`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    BasicSGDClassifier\n",
    "        A trained `BasicSGDClassifier` instance.\n",
    "    \n",
    "    \"\"\"    \n",
    "    mod = BasicSGDClassifier()\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, an SGD classifier trained on unigrams for the unmodified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.761\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.699     0.558     0.620       891\n",
      "        opp      0.785     0.870     0.825      1651\n",
      "\n",
      "avg / total      0.755     0.761     0.754      2542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = sst.experiment(\n",
    "    unigrams_phi,\n",
    "    fit_basic_sgd_classifier,\n",
    "    train_reader=train_reader, \n",
    "    assess_reader=test_reader,\n",
    "    class_func=cas_to_gov,\n",
    "    score_func=utils.safe_macro_f1,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, an SGD classifier trained on unigrams for the modified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.754\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.751     0.435     0.551       881\n",
      "        opp      0.755     0.924     0.831      1661\n",
      "\n",
      "avg / total      0.754     0.754     0.734      2542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = sst.experiment(\n",
    "    unigrams_phi,\n",
    "    fit_basic_sgd_classifier,\n",
    "    train_reader=anon_train_reader, \n",
    "    assess_reader=anon_test_reader,\n",
    "    class_func=cas_to_gov,\n",
    "    score_func=utils.safe_macro_f1,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, an SGD classifier trained on bigrams from the modified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.789\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.737     0.610     0.667       881\n",
      "        opp      0.810     0.884     0.846      1661\n",
      "\n",
      "avg / total      0.785     0.789     0.784      2542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = sst.experiment(\n",
    "    bigrams_phi,\n",
    "    fit_basic_sgd_classifier,\n",
    "    train_reader=anon_train_reader, \n",
    "    assess_reader=anon_test_reader,\n",
    "    class_func=cas_to_gov,\n",
    "    score_func=utils.safe_macro_f1,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_maxent_classifier(X, y):   \n",
    "    mod = LogisticRegression(fit_intercept=True)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we start with unigrams for the basic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.782\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.716     0.626     0.668       891\n",
      "        opp      0.811     0.866     0.838      1651\n",
      "\n",
      "avg / total      0.778     0.782     0.778      2542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = sst.experiment(\n",
    "    unigrams_phi,\n",
    "    fit_maxent_classifier,\n",
    "    train_reader=train_reader, \n",
    "    assess_reader=test_reader,\n",
    "    class_func=cas_to_gov,\n",
    "    score_func=utils.safe_macro_f1,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now unigrams for the modified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.777\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.712     0.600     0.651       881\n",
      "        opp      0.804     0.871     0.836      1661\n",
      "\n",
      "avg / total      0.772     0.777     0.772      2542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = sst.experiment(\n",
    "    unigrams_phi,\n",
    "    fit_maxent_classifier,\n",
    "    train_reader=anon_train_reader, \n",
    "    assess_reader=anon_test_reader,\n",
    "    class_func=cas_to_gov,\n",
    "    score_func=utils.safe_macro_f1,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now bigrams on the modified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.792\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.749     0.600     0.667       881\n",
      "        opp      0.808     0.893     0.849      1661\n",
      "\n",
      "avg / total      0.788     0.792     0.786      2542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = sst.experiment(\n",
    "    bigrams_phi,\n",
    "    fit_maxent_classifier,\n",
    "    train_reader=anon_train_reader, \n",
    "    assess_reader=anon_test_reader,\n",
    "    class_func=cas_to_gov,\n",
    "    score_func=utils.safe_macro_f1,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression without using sst.experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, choose the feature function to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = unigrams_phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, choose the reader used for testing. (None gives a random split.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_reader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're doing a split, what size should we train on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, choose a function for the classes. (We probably want cas_to_gov.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_func = cas_to_gov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we want to vectorise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Classifier\n",
    "\n",
    "Which classifier are we to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make it into a training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(X, y):   \n",
    "    mod = classifier\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sst.build_dataset(train_reader, phi, class_func, vectorize=vectorize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the experiment\n",
    "\n",
    "First, get the data into standardised variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['X']\n",
    "y_train = train['y']\n",
    "X_assess = None\n",
    "y_assess = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're not using an assess_reader, do a split on the training data. Otherwise, read in the assessment dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if assess_reader == None:\n",
    "     X_train, X_assess, y_train, y_assess = train_test_split(\n",
    "            X_train, y_train, train_size=train_size, test_size=None)\n",
    "else:\n",
    "    # Assessment dataset using the training vectorizer:\n",
    "    assess = sst.build_dataset(\n",
    "        assess_reader,\n",
    "        phi,\n",
    "        class_func,\n",
    "        vectorizer=train['vectorizer'],\n",
    "        vectorize=vectorize)\n",
    "    X_assess, y_assess = assess['X'], assess['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment\n",
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = train_func(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mod.predict(X_assess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.768\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.677     0.603     0.638      1020\n",
      "        opp      0.807     0.853     0.829      1987\n",
      "\n",
      "avg / total      0.763     0.768     0.764      3007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %0.03f' % sst.accuracy_score(y_assess, predictions))\n",
    "print(classification_report(y_assess, predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be fairly straightforward. We do Logistic Regression again, but we use GloVe embeddings, rather than the bag of words embeddings from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Setup\n",
    "\n",
    "First, we need the GloVe lookup function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_lookup = utils.glove2dict(\n",
    "    os.path.join(glove_home, 'glove.6B.50d.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a feature function based on the GloVe embeddings. The important parameter here is how we combine vectors for different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vsm_words_phi(sentence, lookup, np_func=np.sum):\n",
    "    \"\"\"Represent `sentence` as a combination of the vector of its words.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tree : A string   \n",
    "    lookup : dict\n",
    "        From words to vectors.\n",
    "    np_func : function (default: np.sum)\n",
    "        A numpy matrix operation that can be applied columnwise, \n",
    "        like `np.mean`, `np.sum`, or `np.prod`. The requirement is that \n",
    "        the function take `axis=0` as one of its arguments (to ensure\n",
    "        columnwise combination) and that it return a vector of a \n",
    "        fixed length, no matter what the size of the tree is.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array, dimension `X.shape[1]`\n",
    "            \n",
    "    \"\"\"      \n",
    "    allvecs = np.array([lookup[w] for w in sentence.split() if w in lookup])    \n",
    "    if len(allvecs) == 0:\n",
    "        dim = len(next(iter(lookup.values())))\n",
    "        feats = np.zeros(dim)\n",
    "    else:       \n",
    "        feats = np_func(allvecs, axis=0)      \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_words_phi(sentence, np_func=np.sum):\n",
    "    return vsm_words_phi(sentence, glove_lookup, np_func=np_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the Training/Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sst.build_dataset(anon_train_reader, glove_words_phi, cas_to_gov, vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['X']\n",
    "y_train = train['y']\n",
    "X_assess = None\n",
    "y_assess = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're not using an assess_reader, do a split on the training data. Otherwise, read in the assessment dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'assess_reader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d24931dcaecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0massess_reader\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m      X_train, X_assess, y_train, y_assess = train_test_split(\n\u001b[1;32m      3\u001b[0m             X_train, y_train, train_size=train_size, test_size=None)\n\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Assessment dataset using the training vectorizer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'assess_reader' is not defined"
     ]
    }
   ],
   "source": [
    "if assess_reader == None:\n",
    "     X_train, X_assess, y_train, y_assess = train_test_split(\n",
    "            X_train, y_train, train_size=train_size, test_size=None)\n",
    "else:\n",
    "    # Assessment dataset using the training vectorizer:\n",
    "    assess = sst.build_dataset(\n",
    "        assess_reader,\n",
    "        phi,\n",
    "        class_func,\n",
    "        vectorizer=train['vectorizer'],\n",
    "        vectorize=vectorize)\n",
    "    X_assess, y_assess = assess['X'], assess['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, we'll do some grid searching. In order to show how to make this work in general, here we'll step through the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a base model to do a grid search on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemod = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify a parameter grid to search over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'fit_intercept': [True, False], \n",
    "                  'C': [0.4, 0.6, 0.8, 1.0, 2.0, 3.0],\n",
    "                  'penalty': ['l1','l2']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many fold cross-validation? (Default is None.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What score metric should be used? (Some function is required here, unless the basemod provides its own.). Options include 'f1_macro', 'f1_micro' and 'accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'f1_macro'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_classifier = GridSearchCV(basemod, param_grid, cv=cv, scoring=scoring,verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.4, fit_intercept=True, penalty=l1, score=0.644543794940576, total=   4.2s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l1, score=0.665227082752856, total=   9.9s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   14.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l1, score=0.6361557844808419, total=   3.5s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   17.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l1, score=0.6396433754924321, total=   3.0s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   20.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l1, score=0.6061868716340213, total=   5.6s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l2 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   26.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l2, score=0.6427753561094345, total=   0.4s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l2 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   26.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l2, score=0.6635259277731884, total=   0.5s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l2 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   27.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l2, score=0.6396409552099758, total=   0.4s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l2 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   27.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l2, score=0.6396243291592129, total=   0.4s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l2 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   28.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l2, score=0.6152210028191704, total=   0.3s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l1, score=0.651792916481798, total=   3.4s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l1, score=0.6587110805860805, total=   4.2s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l1, score=0.6476042467510847, total=   3.6s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l1, score=0.6540214239214063, total=   3.0s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l1, score=0.6332325888017853, total=   3.2s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l2, score=0.6490377358490567, total=   0.2s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l2, score=0.6579755914275115, total=   0.3s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l2, score=0.6508159958671864, total=   0.3s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l2, score=0.6565601524781264, total=   0.2s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l2, score=0.6325097809310729, total=   0.3s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l1, score=0.643971659435577, total=   5.3s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l1, score=0.6669983680292958, total=  19.4s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l1, score=0.6349716101088732, total=   4.1s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l1, score=0.6378577817531306, total=   3.1s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l1, score=0.6087094188276033, total=   5.9s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l2, score=0.6427753561094345, total=   0.3s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l2, score=0.6610718464895191, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l2, score=0.6396409552099758, total=   0.3s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l2, score=0.6396243291592129, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l2, score=0.6158562787576929, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l1, score=0.651792916481798, total=   4.0s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l1, score=0.6591914154872724, total=   7.0s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l1, score=0.6508159958671864, total=   3.0s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l1, score=0.6551149831778559, total=   3.1s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l1, score=0.6336913388543823, total=   3.4s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l2, score=0.6501148100552043, total=   0.3s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l2, score=0.6573683450698578, total=   0.3s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l2, score=0.6508159958671864, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l2, score=0.6571676551424852, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l2, score=0.631919598422528, total=   0.3s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l1, score=0.6445705927205391, total=   5.4s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l1, score=0.662911549166623, total=  23.6s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l1, score=0.6361338112217516, total=   4.7s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l1, score=0.6384336216669436, total=   3.5s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l1, score=0.6092804798687151, total=   7.8s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l2, score=0.6416033885855229, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l2, score=0.6610718464895191, total=   0.3s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l2, score=0.6396409552099758, total=   0.3s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l2, score=0.6396243291592129, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l2, score=0.6140062715588773, total=   0.3s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l1, score=0.6529999463078378, total=   3.8s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l1, score=0.6602776563118175, total=   8.8s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l1, score=0.6491452590053068, total=   3.5s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l1, score=0.6559530851060669, total=   3.9s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l1, score=0.6347276915430493, total=   4.0s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l2, score=0.6501148100552043, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l2, score=0.6562824012860635, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l2, score=0.6508159958671864, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l2, score=0.6565601524781264, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l2, score=0.631919598422528, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l1, score=0.6445705927205391, total=   5.6s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l1, score=0.662911549166623, total=  26.3s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1.0, fit_intercept=True, penalty=l1, score=0.6372937496921637, total=   3.7s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l1, score=0.6384336216669436, total=   3.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l1, score=0.6104961338101258, total=   5.5s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l2, score=0.6422003741591371, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l2, score=0.6622281832519901, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l2, score=0.6396409552099758, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l2, score=0.6396243291592129, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l2, score=0.6152797856199927, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l1, score=0.6523962264150944, total=   3.9s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l1, score=0.6602776563118175, total=  13.0s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l1, score=0.6497472544579261, total=   3.0s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l1, score=0.6565601524781264, total=   3.0s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l1, score=0.6336197388455185, total=   4.0s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l2, score=0.6501148100552043, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l2, score=0.6562824012860635, total=   0.3s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l2, score=0.6508159958671864, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l2, score=0.6571676551424852, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l2, score=0.6308084373242723, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l1, score=0.6422003741591371, total=   6.3s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l1, score=0.6640704604515818, total=   4.8s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l1, score=0.6343980829565948, total=   4.8s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l1, score=0.6384336216669436, total=   3.2s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l1, score=0.6111361994219653, total=   8.4s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l2, score=0.6439450014301217, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l2, score=0.6610718464895191, total=   0.4s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l2, score=0.6396409552099758, total=   1.4s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l2, score=0.6396243291592129, total=   0.3s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l2, score=0.6152797856199927, total=   0.7s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l1, score=0.651792916481798, total=   5.1s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l1, score=0.655800285293116, total=  21.4s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l1, score=0.650349642128232, total=   3.5s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l1, score=0.6582519743871011, total=   3.6s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l1, score=0.6352410608826372, total=   4.0s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l2, score=0.6501148100552043, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l2, score=0.6573683450698578, total=   0.3s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l2, score=0.6508159958671864, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l2, score=0.6571676551424852, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l2, score=0.631919598422528, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l1, score=0.643373248394977, total=  10.0s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l1, score=0.6622977452033052, total=  31.9s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l1, score=0.6349895079069279, total=   4.3s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l1, score=0.6372448979591836, total=   4.6s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l1, score=0.6134945410057003, total=   9.0s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l2, score=0.643373248394977, total=   0.2s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l2, score=0.6628417062989733, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l2, score=0.6396409552099758, total=   0.2s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l2, score=0.6396243291592129, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l2, score=0.6158562787576929, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l1, score=0.6511900135429547, total=   4.9s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l1, score=0.6568889047538307, total=  22.3s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l1, score=0.6497472544579261, total=   4.5s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l1, score=0.6582519743871011, total=   3.6s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l1, score=0.6341359019987906, total=   4.7s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l2 ..........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=3.0, fit_intercept=False, penalty=l2, score=0.6501148100552043, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l2, score=0.6562824012860635, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l2, score=0.6508159958671864, total=   0.2s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l2, score=0.6571676551424852, total=   0.3s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l2, score=0.6308084373242723, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'fit_intercept': [True, False], 'C': [0.4, 0.6, 0.8, 1.0, 2.0, 3.0], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_macro', verbose=10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get some reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 0.8, 'fit_intercept': False, 'penalty': 'l1'}\n",
      "Best score: 0.651\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params\", grid_classifier.best_params_)\n",
    "print(\"Best score: %0.03f\" % grid_classifier.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mod = grid_classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = final_mod.predict(X_assess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.708\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.613     0.424     0.501      1055\n",
      "        opp      0.738     0.859     0.794      1995\n",
      "\n",
      "avg / total      0.695     0.708     0.693      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %0.03f' % sst.accuracy_score(y_assess, predictions))\n",
    "print(classification_report(y_assess, predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_reader = None\n",
    "train_size = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_grid(np_func=np.sum):\n",
    "    def glove_words_phi(sentence):\n",
    "        return vsm_words_phi(sentence, glove_lookup, np_func=np_func)\n",
    "    train = sst.build_dataset(anon_train_reader, glove_words_phi, cas_to_gov, vectorize=False)\n",
    "    X_train = train['X']\n",
    "    y_train = train['y']\n",
    "    X_assess = None\n",
    "    y_assess = None\n",
    "    if assess_reader == None:\n",
    "         X_train, X_assess, y_train, y_assess = train_test_split(\n",
    "                X_train, y_train, train_size=train_size, test_size=None)\n",
    "    else:\n",
    "        # Assessment dataset using the training vectorizer:\n",
    "        assess = sst.build_dataset(\n",
    "            assess_reader,\n",
    "            glove_words_phi,\n",
    "            cas_to_gov,\n",
    "            vectorize=False)\n",
    "        X_assess, y_assess = assess['X'], assess['y']\n",
    "    \n",
    "    grid_classifier = GridSearchCV(LogisticRegression(), {'fit_intercept': [True, False], \n",
    "                  'C': [0.4, 0.6, 0.8, 1.0, 2.0, 3.0],\n",
    "                  'penalty': ['l1','l2']}, cv=3, scoring='f1_macro',verbose=3)\n",
    "    grid_classifier.fit(X_train, y_train)\n",
    "    print(\"Best params\", grid_classifier.best_params_)\n",
    "    print(\"Best score: %0.03f\" % grid_classifier.best_score_)\n",
    "    final_mod = grid_classifier.best_estimator_\n",
    "    predictions = final_mod.predict(X_assess)\n",
    "    print('Accuracy: %0.03f' % sst.accuracy_score(y_assess, predictions))\n",
    "    print(classification_report(y_assess, predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.4, fit_intercept=True, penalty=l1, score=0.6159256365833924, total=  21.3s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   21.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l1, score=0.6308345168290486, total=   3.5s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   24.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, fit_intercept=True, penalty=l1, score=0.6187489950152758, total=  10.1s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.4, fit_intercept=True, penalty=l2, score=0.6137539693995382, total=   0.2s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.4, fit_intercept=True, penalty=l2, score=0.6347686673356351, total=   0.2s\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.4, fit_intercept=True, penalty=l2, score=0.618078251895724, total=   0.2s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l1, score=0.6473232280260274, total=   6.1s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l1, score=0.6407911076112305, total=   4.0s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l1, score=0.6219634369922408, total=  12.5s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l2, score=0.6477886982092547, total=   0.2s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l2, score=0.6443778110944527, total=   0.2s\n",
      "[CV] C=0.4, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.4, fit_intercept=False, penalty=l2, score=0.6208974198982935, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l1, score=0.6152343798335814, total=  20.6s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l1, score=0.6318949588525917, total=   5.7s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l1, score=0.6177077438536922, total=  25.5s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l2, score=0.6141337507919726, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l2, score=0.6347686673356351, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.6, fit_intercept=True, penalty=l2, score=0.6187946470916282, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l1, score=0.6465411941579191, total=  10.8s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l1, score=0.640387182045534, total=   4.4s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l1, score=0.62297355196378, total=  21.7s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l2, score=0.6467736800484742, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l2, score=0.6436601809101639, total=   0.2s\n",
      "[CV] C=0.6, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.6, fit_intercept=False, penalty=l2, score=0.6205485619592879, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l1, score=0.6152343798335814, total=  24.4s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l1, score=0.6318949588525917, total=   7.4s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l1, score=0.6180546615450254, total=  24.7s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l2, score=0.6148239030023095, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l2, score=0.6326028559566927, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=0.8, fit_intercept=True, penalty=l2, score=0.6191421007762372, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l1, score=0.6482148245686226, total=  12.1s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l1, score=0.6420781996276209, total=   4.5s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l1, score=0.6205672805368009, total=  23.7s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l2, score=0.6467736800484742, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l2, score=0.6443221908915223, total=   0.2s\n",
      "[CV] C=0.8, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=0.8, fit_intercept=False, penalty=l2, score=0.6198700416324352, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l1, score=0.6145120919093152, total=  23.7s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l1, score=0.6311719430811428, total=   6.5s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l1, score=0.621618448923414, total=  15.1s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l2, score=0.6148239030023095, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l2, score=0.6326028559566927, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=1.0, fit_intercept=True, penalty=l2, score=0.6184253556653838, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l1, score=0.6488706053180169, total=  12.4s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l1, score=0.6426921763191666, total=   5.4s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l1, score=0.6198873873140973, total=  25.7s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l2, score=0.6467736800484742, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l2, score=0.6443778110944527, total=   0.2s\n",
      "[CV] C=1.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=1.0, fit_intercept=False, penalty=l2, score=0.6198700416324352, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l1, score=0.6141337507919726, total=  12.0s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l1, score=0.6329712893822625, total=   9.0s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l1, score=0.6198579814093642, total=  18.2s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l2, score=0.6144787440688371, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l2, score=0.6340476199119333, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=2.0, fit_intercept=True, penalty=l2, score=0.6184253556653838, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l1, score=0.6464137694008609, total=  17.1s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l1 ..........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=2.0, fit_intercept=False, penalty=l1, score=0.6446812119104214, total=   4.7s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l1, score=0.6219247981641517, total=  30.0s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l2, score=0.6467736800484742, total=   0.1s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l2, score=0.6436601809101639, total=   0.2s\n",
      "[CV] C=2.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=2.0, fit_intercept=False, penalty=l2, score=0.6198700416324352, total=   0.2s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l1, score=0.6141337507919726, total=  12.7s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l1, score=0.6322488133203218, total=  11.4s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l1 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l1, score=0.6198579814093642, total=  30.0s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l2, score=0.6144787440688371, total=   0.2s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l2, score=0.6322488133203218, total=   0.2s\n",
      "[CV] C=3.0, fit_intercept=True, penalty=l2 ...........................\n",
      "[CV]  C=3.0, fit_intercept=True, penalty=l2, score=0.6177077438536922, total=   0.2s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l1, score=0.6464137694008609, total=  17.8s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l1, score=0.6450403860385509, total=   5.1s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l1 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l1, score=0.621226329324363, total=  14.7s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l2, score=0.6467736800484742, total=   0.1s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l2, score=0.6443778110944527, total=   0.2s\n",
      "[CV] C=3.0, fit_intercept=False, penalty=l2 ..........................\n",
      "[CV]  C=3.0, fit_intercept=False, penalty=l2, score=0.6198700416324352, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  8.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 0.4, 'fit_intercept': False, 'penalty': 'l2'}\n",
      "Best score: 0.638\n",
      "Accuracy: 0.693\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.593     0.385     0.467      1063\n",
      "        opp      0.723     0.859     0.785      1987\n",
      "\n",
      "avg / total      0.678     0.693     0.674      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_logistic_grid(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/declan/anaconda3/envs/nlu/lib/python3.6/site-packages/numpy/core/_methods.py:35: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_prod(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] C=0.4, fit_intercept=True, penalty=l1 ...........................\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-269c737f276f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_logistic_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-38e4f7cc64ab>\u001b[0m in \u001b[0;36mrun_logistic_grid\u001b[0;34m(np_func)\u001b[0m\n\u001b[1;32m     22\u001b[0m                   \u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                   'penalty': ['l1','l2']}, cv=3, scoring='f1_macro',verbose=3)\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mgrid_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best params\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best score: %0.03f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgrid_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \"\"\"\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     99\u001b[0m         super(_PredictScorer, self).__call__(estimator, X, y_true,\n\u001b[1;32m    100\u001b[0m                                              sample_weight=sample_weight)\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    298\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "run_logistic_grid(np.prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these, the best on the training set is 0.674 with params {'C': 0.4, 'fit_intercept': False, 'penalty': 'l2'}. So we'll take that as our function and run it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_reader = anon_test_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.716\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov      0.636     0.419     0.505       881\n",
      "        opp      0.739     0.873     0.800      1661\n",
      "\n",
      "avg / total      0.703     0.716     0.698      2542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def glove_words_phi(sentence, np_func=np.sum):\n",
    "    return vsm_words_phi(sentence, glove_lookup, np_func=np_func)\n",
    "train = sst.build_dataset(anon_train_reader, glove_words_phi, cas_to_gov, vectorize=False)\n",
    "X_train = train['X']\n",
    "y_train = train['y']\n",
    "X_assess = None\n",
    "y_assess = None\n",
    "if assess_reader == None:\n",
    "     X_train, X_assess, y_train, y_assess = train_test_split(\n",
    "            X_train, y_train, train_size=train_size, test_size=None)\n",
    "else:\n",
    "    # Assessment dataset using the training vectorizer:\n",
    "    assess = sst.build_dataset(\n",
    "        assess_reader,\n",
    "        glove_words_phi,\n",
    "        cas_to_gov,\n",
    "        vectorize=False)\n",
    "    X_assess, y_assess = assess['X'], assess['y']\n",
    "\n",
    "grid_classifier = LogisticRegression(C=0.4, fit_intercept=False, penalty='l2')\n",
    "grid_classifier.fit(X_train, y_train)\n",
    "# print(\"Best params\", grid_classifier.best_params_)\n",
    "# print(\"Best score: %0.03f\" % grid_classifier.best_score_)\n",
    "# final_mod = grid_classifier.best_estimator_\n",
    "predictions = grid_classifier.predict(X_assess)\n",
    "print('Accuracy: %0.03f' % sst.accuracy_score(y_assess, predictions))\n",
    "print(classification_report(y_assess, predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should use the tensorflow RNN set-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Input Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(question.split(), label) for question, label in train_reader(class_func=cas_to_gov)]\n",
    "X, y = zip(*train_data)\n",
    "X_rnn_train = list(X)\n",
    "y_rnn_train = list(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have a devoted dev set, make a 70-30 split in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rnn_train, X_rnn_assess, y_rnn_train, y_rnn_assess = train_test_split(X_rnn_train, y_rnn_train, train_size=0.7, test_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorflow implementation requires that we specify a maximum length up front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 1,123\n",
      "Min sequence length: 0\n",
      "Mean sequence length: 71.78\n",
      "Median sequence length: 69.00\n",
      "Sequences longer than 150: 225 of 7,115\n"
     ]
    }
   ],
   "source": [
    "utils.sequence_length_report(X_rnn_train, potential_max_length=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, we might take this maximum length to be 150."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hansard_full_train_vocab = sst.get_vocab(X_rnn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hansard_full_train_vocab has 35,337 items\n"
     ]
    }
   ],
   "source": [
    "print(\"hansard_full_train_vocab has {:,} items\".format(len(hansard_full_train_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hansard_train_vocab = sst.get_vocab(X_rnn_train, n_words=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rnn = TfRNNClassifier(\n",
    "    hansard_train_vocab,\n",
    "    embed_dim=50,\n",
    "    hidden_dim=50,\n",
    "    max_length=150,\n",
    "    hidden_activation=tf.nn.tanh,\n",
    "    cell_class=tf.nn.rnn_cell.LSTMCell,\n",
    "    train_embedding=True,\n",
    "    max_iter=10,\n",
    "    eta=0.05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 10: loss: 4.548222303390503"
     ]
    }
   ],
   "source": [
    "_ = tf_rnn.fit(X_rnn_train, y_rnn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rnn_dev_predictions = tf_rnn.predict(X_rnn_assess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        gov       0.00      0.00      0.00      1039\n",
      "        opp       0.66      1.00      0.79      2011\n",
      "\n",
      "avg / total       0.43      0.66      0.52      3050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_rnn_assess, tf_rnn_dev_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long/Short Term Memory Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
